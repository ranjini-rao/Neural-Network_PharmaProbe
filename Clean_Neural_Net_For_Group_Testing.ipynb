{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "id": "4VyNnOMB6NR1",
        "outputId": "4e78e3b9-060d-4e01-b1b4-4a4823c7f231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   uniqueID                 drugName                     condition  \\\n",
              "0     95260               Guanfacine                          ADHD   \n",
              "1     92703                   Lybrel                 Birth Control   \n",
              "2    138000               Ortho Evra                 Birth Control   \n",
              "3     35696  Buprenorphine  naloxone             Opiate Dependence   \n",
              "4    155963                   Cialis  Benign Prostatic Hyperplasia   \n",
              "\n",
              "                                              review  rating       date  \\\n",
              "0  My son is halfway through his fourth week of I...     8.0  27-Apr-10   \n",
              "1  I used to take another oral contraceptive whic...     5.0  14-Dec-09   \n",
              "2  This is my first time using any form of birth ...     8.0   3-Nov-15   \n",
              "3  Suboxone has completely turned my life around ...     9.0  27-Nov-16   \n",
              "4  2nd day on 5mg started to work with rock hard ...     2.0  28-Nov-15   \n",
              "\n",
              "   usefulCount  lengthReview  conditionCluster_label  drugNameCluster_label  \\\n",
              "0        192.0         712.0                     2.0                    4.0   \n",
              "1         17.0         708.0                     9.0                    6.0   \n",
              "2         10.0         428.0                     9.0                    4.0   \n",
              "3         37.0         669.0                     0.0                    2.0   \n",
              "4         43.0         373.0                     0.0                    5.0   \n",
              "\n",
              "   ...       758       759       760       761       762       763       764  \\\n",
              "0  ... -0.416409 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359   \n",
              "1  ... -0.279307 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790   \n",
              "2  ... -0.232733 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650   \n",
              "3  ... -0.310564 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821   \n",
              "4  ... -0.247983 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261   \n",
              "\n",
              "        765       766       767  \n",
              "0 -0.541467  0.062160  0.049585  \n",
              "1 -0.706709  0.047264 -0.017902  \n",
              "2 -0.693634 -0.024901  0.548486  \n",
              "3 -0.710691  0.065533  0.371945  \n",
              "4 -0.527391 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 778 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-751113e8-a86d-437f-b758-8327fb9c143a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniqueID</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>lengthReview</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>drugNameCluster_label</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>95260</td>\n",
              "      <td>Guanfacine</td>\n",
              "      <td>ADHD</td>\n",
              "      <td>My son is halfway through his fourth week of I...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>27-Apr-10</td>\n",
              "      <td>192.0</td>\n",
              "      <td>712.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92703</td>\n",
              "      <td>Lybrel</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>I used to take another oral contraceptive whic...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14-Dec-09</td>\n",
              "      <td>17.0</td>\n",
              "      <td>708.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138000</td>\n",
              "      <td>Ortho Evra</td>\n",
              "      <td>Birth Control</td>\n",
              "      <td>This is my first time using any form of birth ...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3-Nov-15</td>\n",
              "      <td>10.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35696</td>\n",
              "      <td>Buprenorphine  naloxone</td>\n",
              "      <td>Opiate Dependence</td>\n",
              "      <td>Suboxone has completely turned my life around ...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27-Nov-16</td>\n",
              "      <td>37.0</td>\n",
              "      <td>669.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>155963</td>\n",
              "      <td>Cialis</td>\n",
              "      <td>Benign Prostatic Hyperplasia</td>\n",
              "      <td>2nd day on 5mg started to work with rock hard ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28-Nov-15</td>\n",
              "      <td>43.0</td>\n",
              "      <td>373.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 778 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-751113e8-a86d-437f-b758-8327fb9c143a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-751113e8-a86d-437f-b758-8327fb9c143a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-751113e8-a86d-437f-b758-8327fb9c143a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1528b52d-6ce7-4eb1-9a30-586dd0798412\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1528b52d-6ce7-4eb1-9a30-586dd0798412')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1528b52d-6ce7-4eb1-9a30-586dd0798412 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "embedded_df = pd.read_csv('embedded_review.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify it was loaded correctly\n",
        "embedded_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedded_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daKqS3a96i-l",
        "outputId": "41d8bb00-d9e2-4271-ac6e-b3061bd242e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11316"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This Neural Net is just going to focus on classifying the Condition Cluster by the Review Embeddings\n",
        "#This Neural Net is also going to use the dataframe that has not had dimensions reduced\n",
        "\n",
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xr4mDZzP6nvX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I am going to drop the columns that are not embeddings of the review and the condition_cluster\n",
        "\n",
        "columns_to_drop = ['uniqueID', 'drugName', 'date', 'condition', 'review', 'lengthReview']\n",
        "\n",
        "embedded_df.drop(columns=columns_to_drop, inplace=True)"
      ],
      "metadata": {
        "id": "ytUNWz5_6pvE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the dataframe\n",
        "\n",
        "embedded_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "VGRdZ9WN6sC6",
        "outputId": "61aa31aa-9172-4917-feac-0377d8ca95cf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating  usefulCount  conditionCluster_label  drugNameCluster_label  \\\n",
              "0     8.0        192.0                     2.0                    4.0   \n",
              "1     5.0         17.0                     9.0                    6.0   \n",
              "2     8.0         10.0                     9.0                    4.0   \n",
              "3     9.0         37.0                     0.0                    2.0   \n",
              "4     2.0         43.0                     0.0                    5.0   \n",
              "\n",
              "          0         1         2         3         4         5  ...       758  \\\n",
              "0 -0.010977  0.010914  0.200967 -0.229490 -0.535286  0.012419  ... -0.416409   \n",
              "1  0.066320  0.189584  0.369006 -0.046920 -0.473988 -0.238288  ... -0.279307   \n",
              "2  0.084101 -0.019134  0.294494  0.029783 -0.228783  0.170102  ... -0.232733   \n",
              "3  0.007820  0.207558  0.179105 -0.210057 -0.197015  0.104799  ... -0.310564   \n",
              "4 -0.193177  0.360585  0.448292 -0.253824 -0.532782  0.085381  ... -0.247983   \n",
              "\n",
              "        759       760       761       762       763       764       765  \\\n",
              "0 -0.364040 -0.036060  0.383963  0.176255 -0.147201 -0.243359 -0.541467   \n",
              "1 -0.419729 -0.389261  0.328398  0.291834 -0.027217 -0.359790 -0.706709   \n",
              "2 -0.031823 -0.032784  0.188440  0.162272  0.363399 -0.096650 -0.693634   \n",
              "3 -0.599643 -0.375174  0.309915  0.577983  0.051811 -0.184821 -0.710691   \n",
              "4 -0.438636 -0.037911 -0.030183  0.508780  0.064493 -0.205261 -0.527391   \n",
              "\n",
              "        766       767  \n",
              "0  0.062160  0.049585  \n",
              "1  0.047264 -0.017902  \n",
              "2 -0.024901  0.548486  \n",
              "3  0.065533  0.371945  \n",
              "4 -0.101341  0.039573  \n",
              "\n",
              "[5 rows x 772 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b48f818-8513-4c1b-95fe-55eda2086827\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>usefulCount</th>\n",
              "      <th>conditionCluster_label</th>\n",
              "      <th>drugNameCluster_label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>...</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>-0.010977</td>\n",
              "      <td>0.010914</td>\n",
              "      <td>0.200967</td>\n",
              "      <td>-0.229490</td>\n",
              "      <td>-0.535286</td>\n",
              "      <td>0.012419</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.416409</td>\n",
              "      <td>-0.364040</td>\n",
              "      <td>-0.036060</td>\n",
              "      <td>0.383963</td>\n",
              "      <td>0.176255</td>\n",
              "      <td>-0.147201</td>\n",
              "      <td>-0.243359</td>\n",
              "      <td>-0.541467</td>\n",
              "      <td>0.062160</td>\n",
              "      <td>0.049585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.066320</td>\n",
              "      <td>0.189584</td>\n",
              "      <td>0.369006</td>\n",
              "      <td>-0.046920</td>\n",
              "      <td>-0.473988</td>\n",
              "      <td>-0.238288</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.279307</td>\n",
              "      <td>-0.419729</td>\n",
              "      <td>-0.389261</td>\n",
              "      <td>0.328398</td>\n",
              "      <td>0.291834</td>\n",
              "      <td>-0.027217</td>\n",
              "      <td>-0.359790</td>\n",
              "      <td>-0.706709</td>\n",
              "      <td>0.047264</td>\n",
              "      <td>-0.017902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.084101</td>\n",
              "      <td>-0.019134</td>\n",
              "      <td>0.294494</td>\n",
              "      <td>0.029783</td>\n",
              "      <td>-0.228783</td>\n",
              "      <td>0.170102</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.232733</td>\n",
              "      <td>-0.031823</td>\n",
              "      <td>-0.032784</td>\n",
              "      <td>0.188440</td>\n",
              "      <td>0.162272</td>\n",
              "      <td>0.363399</td>\n",
              "      <td>-0.096650</td>\n",
              "      <td>-0.693634</td>\n",
              "      <td>-0.024901</td>\n",
              "      <td>0.548486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.207558</td>\n",
              "      <td>0.179105</td>\n",
              "      <td>-0.210057</td>\n",
              "      <td>-0.197015</td>\n",
              "      <td>0.104799</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310564</td>\n",
              "      <td>-0.599643</td>\n",
              "      <td>-0.375174</td>\n",
              "      <td>0.309915</td>\n",
              "      <td>0.577983</td>\n",
              "      <td>0.051811</td>\n",
              "      <td>-0.184821</td>\n",
              "      <td>-0.710691</td>\n",
              "      <td>0.065533</td>\n",
              "      <td>0.371945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>-0.193177</td>\n",
              "      <td>0.360585</td>\n",
              "      <td>0.448292</td>\n",
              "      <td>-0.253824</td>\n",
              "      <td>-0.532782</td>\n",
              "      <td>0.085381</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.247983</td>\n",
              "      <td>-0.438636</td>\n",
              "      <td>-0.037911</td>\n",
              "      <td>-0.030183</td>\n",
              "      <td>0.508780</td>\n",
              "      <td>0.064493</td>\n",
              "      <td>-0.205261</td>\n",
              "      <td>-0.527391</td>\n",
              "      <td>-0.101341</td>\n",
              "      <td>0.039573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 772 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b48f818-8513-4c1b-95fe-55eda2086827')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b48f818-8513-4c1b-95fe-55eda2086827 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b48f818-8513-4c1b-95fe-55eda2086827');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2b84fa57-6eef-4b62-b082-43d55dd2c66a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2b84fa57-6eef-4b62-b082-43d55dd2c66a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2b84fa57-6eef-4b62-b082-43d55dd2c66a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "embedded_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking on why the values of the condition cluster look like a float\n",
        "\n",
        "condition_value_counts = embedded_df['conditionCluster_label'].value_counts()\n",
        "print(condition_value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jMeoThU65Q_",
        "outputId": "2ad3355f-f55e-4072-9686-0f32fad979e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    4074\n",
            "8.0    2100\n",
            "2.0     955\n",
            "1.0     865\n",
            "7.0     777\n",
            "9.0     752\n",
            "4.0     736\n",
            "5.0     356\n",
            "3.0     353\n",
            "6.0     347\n",
            "Name: conditionCluster_label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# When I start training the model I am getting an error messsage that NAN values are present\n",
        "embedded_df = embedded_df.dropna(subset=['conditionCluster_label'])"
      ],
      "metadata": {
        "id": "9IfvnqVh67HQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "# Choosing randon_state = 30 to be able to re-create attempts later\n",
        "# There is a lot of data, so I can train on 70%, setting test_size at .3\n",
        "# This step is necessary for training the neural network to classify 10 categories\n",
        "# This code is altered by chatgpt after I could not fix it on my own\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Separate the target variable\n",
        "target = embedded_df['conditionCluster_label']\n",
        "\n",
        "# Verify the unique values in the target variable\n",
        "print(target.unique())\n",
        "\n",
        "# Extract features (excluding the target variable)\n",
        "features = embedded_df.drop(columns=['conditionCluster_label'])\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=30)\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Check the shapes of the one-hot encoded target labels\n",
        "print(\"Shape of y_train_encoded:\", y_train_encoded.shape)\n",
        "print(\"Shape of y_test_encoded:\", y_test_encoded.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCCETtsI69C7",
        "outputId": "5c5ea7f6-1442-4581-d92d-7de544b09448"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 9. 0. 1. 3. 8. 5. 7. 4. 6.]\n",
            "Shape of y_train_encoded: (7920, 10)\n",
            "Shape of y_test_encoded: (3395, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "O23diebR6__s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the number of dimensions, make it a variable so it passes into\n",
        "\n",
        "num_dimensions = embedded_df.shape[1]-1\n",
        "print(num_dimensions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYq1MvQx7CIg",
        "outputId": "cfa556df-0983-409b-d118-86cb4ce784e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "# Most of this is going to be the same as the HW assignment, but there are 10 classifications to predict now\n",
        "# So the output layer has been adjusted\n",
        "\n",
        "# Changed the number of nodes in the input layer to macth the dimensionality of the input data.\n",
        "# Changed the hidden layer nodes to have relu as their activation funciton\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=771, activation=\"sigmoid\", input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(Dense(units=600, activation='relu'))\n",
        "\n",
        "# Third hidden layer (example of adding an additional hidden layer)\n",
        "nn.add(Dense(units=500, activation='relu'))\n",
        "\n",
        "#Fourth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=400, activation='relu'))\n",
        "\n",
        "#Fifth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=300, activation='relu'))\n",
        "\n",
        "#Sixth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=200, activation='relu'))\n",
        "\n",
        "#Seventh hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=100, activation='relu'))\n",
        "\n",
        "#Eighth hidden layer (example of adding another hidden layer)\n",
        "nn.add(Dense(units=50, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))  # 10 units for 10 classes, softmax activation\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "le9upw8D7tdf",
        "outputId": "8439f006-7cfc-45a8-d5ff-d321b05a2743"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 771)               595212    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 600)               463200    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 500)               300500    \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 400)               200400    \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 300)               120300    \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 200)               60200     \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1765472 (6.73 MB)\n",
            "Trainable params: 1765472 (6.73 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "# Compile the model - the loss function is categorical and not for binary classification\n",
        "custom_optimizer = Adam(learning_rate=0.001)\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=custom_optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "k-g2YqfH7vx_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCMHwJZ-70Vi",
        "outputId": "872ab2c0-20c4-4028-82ec-bfc05fc0b6df"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "248/248 [==============================] - 8s 25ms/step - loss: 1.8610 - accuracy: 0.3587\n",
            "Epoch 2/10\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 1.6944 - accuracy: 0.3793\n",
            "Epoch 3/10\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.5115 - accuracy: 0.4340\n",
            "Epoch 4/10\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 1.4065 - accuracy: 0.4621\n",
            "Epoch 5/10\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.3229 - accuracy: 0.4876\n",
            "Epoch 6/10\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.2343 - accuracy: 0.5139\n",
            "Epoch 7/10\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 1.1520 - accuracy: 0.5395\n",
            "Epoch 8/10\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.0759 - accuracy: 0.5726\n",
            "Epoch 9/10\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 0.9867 - accuracy: 0.6091\n",
            "Epoch 10/10\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.8874 - accuracy: 0.6485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9hNCz472VB",
        "outputId": "eb5e523b-b5ee-446f-f9e9-d7535f2db797"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 5ms/step - loss: 1.7097 - accuracy: 0.4680\n",
            "Test Loss: 1.7096757888793945\n",
            "Test Accuracy: 0.46804124116897583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using L2 Normalization\n",
        "# regularization strength = 0.001\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Define the model - deep neural net with L2 regularization\n",
        "nn = Sequential()\n",
        "\n",
        "# First hidden layer with L2 regularization\n",
        "nn.add(Dense(units=771, activation=\"sigmoid\", kernel_regularizer=regularizers.l2(0.001), input_dim=num_dimensions))\n",
        "\n",
        "# Second hidden layer with L2 regularization\n",
        "nn.add(Dense(units=512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Third hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Fourth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Fifth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=256, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Sixth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Seventh hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Eighth hidden layer with L2 regularization\n",
        "nn.add(Dense(units=64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
        "\n",
        "# Output layer\n",
        "nn.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model to the training data\n",
        "fit_model = nn.fit(X_train_scaled, y_train_encoded, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3WMJtya77HB",
        "outputId": "0c6a2a4d-d0e3-4808-f9ac-694e9bd7be3b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 771)               595212    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 512)               395264    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1299350 (4.96 MB)\n",
            "Trainable params: 1299350 (4.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "248/248 [==============================] - 7s 22ms/step - loss: 2.6724 - accuracy: 0.3577\n",
            "Epoch 2/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.9703 - accuracy: 0.3725\n",
            "Epoch 3/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.8388 - accuracy: 0.4000\n",
            "Epoch 4/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.7628 - accuracy: 0.4109\n",
            "Epoch 5/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.7356 - accuracy: 0.4146\n",
            "Epoch 6/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.6908 - accuracy: 0.4220\n",
            "Epoch 7/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.6819 - accuracy: 0.4189\n",
            "Epoch 8/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.6686 - accuracy: 0.4312\n",
            "Epoch 9/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.6342 - accuracy: 0.4365\n",
            "Epoch 10/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.6273 - accuracy: 0.4376\n",
            "Epoch 11/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.6177 - accuracy: 0.4407\n",
            "Epoch 12/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.6077 - accuracy: 0.4487\n",
            "Epoch 13/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.5856 - accuracy: 0.4501\n",
            "Epoch 14/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.5798 - accuracy: 0.4494\n",
            "Epoch 15/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.5608 - accuracy: 0.4582\n",
            "Epoch 16/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 1.5469 - accuracy: 0.4622\n",
            "Epoch 17/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.5382 - accuracy: 0.4717\n",
            "Epoch 18/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.5158 - accuracy: 0.4775\n",
            "Epoch 19/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.4990 - accuracy: 0.4832\n",
            "Epoch 20/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.5012 - accuracy: 0.4835\n",
            "Epoch 21/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.4837 - accuracy: 0.4896\n",
            "Epoch 22/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.4630 - accuracy: 0.5056\n",
            "Epoch 23/200\n",
            "248/248 [==============================] - 7s 26ms/step - loss: 1.4586 - accuracy: 0.5009\n",
            "Epoch 24/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.4387 - accuracy: 0.5074\n",
            "Epoch 25/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.4198 - accuracy: 0.5216\n",
            "Epoch 26/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.4093 - accuracy: 0.5246\n",
            "Epoch 27/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.3784 - accuracy: 0.5374\n",
            "Epoch 28/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.3657 - accuracy: 0.5471\n",
            "Epoch 29/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.3523 - accuracy: 0.5519\n",
            "Epoch 30/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.3098 - accuracy: 0.5692\n",
            "Epoch 31/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 1.2959 - accuracy: 0.5835\n",
            "Epoch 32/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 1.2712 - accuracy: 0.5904\n",
            "Epoch 33/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.2505 - accuracy: 0.6025\n",
            "Epoch 34/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.2281 - accuracy: 0.6119\n",
            "Epoch 35/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 1.1975 - accuracy: 0.6274\n",
            "Epoch 36/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.1680 - accuracy: 0.6480\n",
            "Epoch 37/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 1.1558 - accuracy: 0.6503\n",
            "Epoch 38/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 1.1186 - accuracy: 0.6734\n",
            "Epoch 39/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 1.0962 - accuracy: 0.6827\n",
            "Epoch 40/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 1.0739 - accuracy: 0.7027\n",
            "Epoch 41/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.0409 - accuracy: 0.7182\n",
            "Epoch 42/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 1.0236 - accuracy: 0.7241\n",
            "Epoch 43/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 0.9951 - accuracy: 0.7439\n",
            "Epoch 44/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.9937 - accuracy: 0.7490\n",
            "Epoch 45/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.9680 - accuracy: 0.7622\n",
            "Epoch 46/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.9422 - accuracy: 0.7771\n",
            "Epoch 47/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.9286 - accuracy: 0.7871\n",
            "Epoch 48/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.8925 - accuracy: 0.8053\n",
            "Epoch 49/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.8883 - accuracy: 0.8053\n",
            "Epoch 50/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.8835 - accuracy: 0.8136\n",
            "Epoch 51/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.8493 - accuracy: 0.8336\n",
            "Epoch 52/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.8463 - accuracy: 0.8359\n",
            "Epoch 53/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.8231 - accuracy: 0.8433\n",
            "Epoch 54/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.8154 - accuracy: 0.8519\n",
            "Epoch 55/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.8431 - accuracy: 0.8439\n",
            "Epoch 56/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7828 - accuracy: 0.8674\n",
            "Epoch 57/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.7888 - accuracy: 0.8693\n",
            "Epoch 58/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7756 - accuracy: 0.8773\n",
            "Epoch 59/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7763 - accuracy: 0.8799\n",
            "Epoch 60/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.7604 - accuracy: 0.8819\n",
            "Epoch 61/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7389 - accuracy: 0.8924\n",
            "Epoch 62/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7357 - accuracy: 0.8939\n",
            "Epoch 63/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.7233 - accuracy: 0.8981\n",
            "Epoch 64/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7430 - accuracy: 0.8956\n",
            "Epoch 65/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.7172 - accuracy: 0.9054\n",
            "Epoch 66/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.7399 - accuracy: 0.8971\n",
            "Epoch 67/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.7006 - accuracy: 0.9091\n",
            "Epoch 68/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.7314 - accuracy: 0.9034\n",
            "Epoch 69/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6932 - accuracy: 0.9202\n",
            "Epoch 70/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6966 - accuracy: 0.9133\n",
            "Epoch 71/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6937 - accuracy: 0.9158\n",
            "Epoch 72/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.7066 - accuracy: 0.9120\n",
            "Epoch 73/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6879 - accuracy: 0.9192\n",
            "Epoch 74/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6871 - accuracy: 0.9217\n",
            "Epoch 75/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6834 - accuracy: 0.9212\n",
            "Epoch 76/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6873 - accuracy: 0.9193\n",
            "Epoch 77/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6879 - accuracy: 0.9213\n",
            "Epoch 78/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6839 - accuracy: 0.9207\n",
            "Epoch 79/200\n",
            "248/248 [==============================] - 6s 25ms/step - loss: 0.6397 - accuracy: 0.9393\n",
            "Epoch 80/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6804 - accuracy: 0.9212\n",
            "Epoch 81/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6903 - accuracy: 0.9168\n",
            "Epoch 82/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6617 - accuracy: 0.9303\n",
            "Epoch 83/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6600 - accuracy: 0.9280\n",
            "Epoch 84/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6926 - accuracy: 0.9157\n",
            "Epoch 85/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6674 - accuracy: 0.9266\n",
            "Epoch 86/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6762 - accuracy: 0.9258\n",
            "Epoch 87/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6383 - accuracy: 0.9410\n",
            "Epoch 88/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6334 - accuracy: 0.9391\n",
            "Epoch 89/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6675 - accuracy: 0.9288\n",
            "Epoch 90/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6684 - accuracy: 0.9260\n",
            "Epoch 91/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6897 - accuracy: 0.9167\n",
            "Epoch 92/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6197 - accuracy: 0.9477\n",
            "Epoch 93/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6659 - accuracy: 0.9284\n",
            "Epoch 94/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6513 - accuracy: 0.9345\n",
            "Epoch 95/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6396 - accuracy: 0.9391\n",
            "Epoch 96/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6387 - accuracy: 0.9374\n",
            "Epoch 97/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6168 - accuracy: 0.9438\n",
            "Epoch 98/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6969 - accuracy: 0.9140\n",
            "Epoch 99/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6297 - accuracy: 0.9426\n",
            "Epoch 100/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6318 - accuracy: 0.9385\n",
            "Epoch 101/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6447 - accuracy: 0.9337\n",
            "Epoch 102/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6421 - accuracy: 0.9354\n",
            "Epoch 103/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6367 - accuracy: 0.9379\n",
            "Epoch 104/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6360 - accuracy: 0.9379\n",
            "Epoch 105/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6435 - accuracy: 0.9354\n",
            "Epoch 106/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6447 - accuracy: 0.9365\n",
            "Epoch 107/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6325 - accuracy: 0.9398\n",
            "Epoch 108/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6361 - accuracy: 0.9391\n",
            "Epoch 109/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6582 - accuracy: 0.9322\n",
            "Epoch 110/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6356 - accuracy: 0.9393\n",
            "Epoch 111/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6143 - accuracy: 0.9465\n",
            "Epoch 112/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6414 - accuracy: 0.9394\n",
            "Epoch 113/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6203 - accuracy: 0.9417\n",
            "Epoch 114/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6413 - accuracy: 0.9367\n",
            "Epoch 115/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6288 - accuracy: 0.9385\n",
            "Epoch 116/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6609 - accuracy: 0.9297\n",
            "Epoch 117/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6174 - accuracy: 0.9437\n",
            "Epoch 118/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6195 - accuracy: 0.9460\n",
            "Epoch 119/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6408 - accuracy: 0.9354\n",
            "Epoch 120/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6055 - accuracy: 0.9513\n",
            "Epoch 121/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6151 - accuracy: 0.9456\n",
            "Epoch 122/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.6003 - accuracy: 0.9472\n",
            "Epoch 123/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6188 - accuracy: 0.9420\n",
            "Epoch 124/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 0.6107 - accuracy: 0.9462\n",
            "Epoch 125/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6398 - accuracy: 0.9343\n",
            "Epoch 126/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6347 - accuracy: 0.9341\n",
            "Epoch 127/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6411 - accuracy: 0.9351\n",
            "Epoch 128/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6369 - accuracy: 0.9388\n",
            "Epoch 129/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6402 - accuracy: 0.9354\n",
            "Epoch 130/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 0.5947 - accuracy: 0.9537\n",
            "Epoch 131/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6202 - accuracy: 0.9395\n",
            "Epoch 132/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5875 - accuracy: 0.9510\n",
            "Epoch 133/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.6165 - accuracy: 0.9412\n",
            "Epoch 134/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6310 - accuracy: 0.9362\n",
            "Epoch 135/200\n",
            "248/248 [==============================] - 6s 24ms/step - loss: 0.5967 - accuracy: 0.9477\n",
            "Epoch 136/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6156 - accuracy: 0.9434\n",
            "Epoch 137/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 0.6244 - accuracy: 0.9413\n",
            "Epoch 138/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6029 - accuracy: 0.9476\n",
            "Epoch 139/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 0.6015 - accuracy: 0.9499\n",
            "Epoch 140/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6167 - accuracy: 0.9428\n",
            "Epoch 141/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.5868 - accuracy: 0.9523\n",
            "Epoch 142/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6306 - accuracy: 0.9341\n",
            "Epoch 143/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5661 - accuracy: 0.9600\n",
            "Epoch 144/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6229 - accuracy: 0.9369\n",
            "Epoch 145/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6176 - accuracy: 0.9412\n",
            "Epoch 146/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6118 - accuracy: 0.9409\n",
            "Epoch 147/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.6131 - accuracy: 0.9437\n",
            "Epoch 148/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.5895 - accuracy: 0.9532\n",
            "Epoch 149/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.5977 - accuracy: 0.9451\n",
            "Epoch 150/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6049 - accuracy: 0.9431\n",
            "Epoch 151/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6389 - accuracy: 0.9336\n",
            "Epoch 152/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6044 - accuracy: 0.9463\n",
            "Epoch 153/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.5788 - accuracy: 0.9542\n",
            "Epoch 154/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6235 - accuracy: 0.9380\n",
            "Epoch 155/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 0.5974 - accuracy: 0.9475\n",
            "Epoch 156/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.5710 - accuracy: 0.9540\n",
            "Epoch 157/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6276 - accuracy: 0.9380\n",
            "Epoch 158/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.5744 - accuracy: 0.9552\n",
            "Epoch 159/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.6343 - accuracy: 0.9322\n",
            "Epoch 160/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5691 - accuracy: 0.9567\n",
            "Epoch 161/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6144 - accuracy: 0.9424\n",
            "Epoch 162/200\n",
            "248/248 [==============================] - 4s 17ms/step - loss: 0.5987 - accuracy: 0.9501\n",
            "Epoch 163/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6135 - accuracy: 0.9398\n",
            "Epoch 164/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.6011 - accuracy: 0.9463\n",
            "Epoch 165/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5653 - accuracy: 0.9590\n",
            "Epoch 166/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6376 - accuracy: 0.9314\n",
            "Epoch 167/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.6096 - accuracy: 0.9404\n",
            "Epoch 168/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5932 - accuracy: 0.9504\n",
            "Epoch 169/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.5803 - accuracy: 0.9511\n",
            "Epoch 170/200\n",
            "248/248 [==============================] - 5s 19ms/step - loss: 0.6521 - accuracy: 0.9285\n",
            "Epoch 171/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5984 - accuracy: 0.9499\n",
            "Epoch 172/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.5725 - accuracy: 0.9568\n",
            "Epoch 173/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6184 - accuracy: 0.9414\n",
            "Epoch 174/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5967 - accuracy: 0.9494\n",
            "Epoch 175/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.5549 - accuracy: 0.9598\n",
            "Epoch 176/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6395 - accuracy: 0.9333\n",
            "Epoch 177/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5716 - accuracy: 0.9552\n",
            "Epoch 178/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.5746 - accuracy: 0.9533\n",
            "Epoch 179/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5981 - accuracy: 0.9472\n",
            "Epoch 180/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.5603 - accuracy: 0.9578\n",
            "Epoch 181/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.5964 - accuracy: 0.9443\n",
            "Epoch 182/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6340 - accuracy: 0.9322\n",
            "Epoch 183/200\n",
            "248/248 [==============================] - 5s 21ms/step - loss: 0.5719 - accuracy: 0.9548\n",
            "Epoch 184/200\n",
            "248/248 [==============================] - 5s 18ms/step - loss: 0.6053 - accuracy: 0.9405\n",
            "Epoch 185/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6093 - accuracy: 0.9433\n",
            "Epoch 186/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.5334 - accuracy: 0.9681\n",
            "Epoch 187/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6504 - accuracy: 0.9251\n",
            "Epoch 188/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5822 - accuracy: 0.9520\n",
            "Epoch 189/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.5671 - accuracy: 0.9571\n",
            "Epoch 190/200\n",
            "248/248 [==============================] - 5s 22ms/step - loss: 0.5969 - accuracy: 0.9434\n",
            "Epoch 191/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.6205 - accuracy: 0.9381\n",
            "Epoch 192/200\n",
            "248/248 [==============================] - 5s 20ms/step - loss: 0.5648 - accuracy: 0.9577\n",
            "Epoch 193/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5897 - accuracy: 0.9458\n",
            "Epoch 194/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 0.5737 - accuracy: 0.9533\n",
            "Epoch 195/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5600 - accuracy: 0.9586\n",
            "Epoch 196/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.6260 - accuracy: 0.9346\n",
            "Epoch 197/200\n",
            "248/248 [==============================] - 6s 23ms/step - loss: 0.5594 - accuracy: 0.9574\n",
            "Epoch 198/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5905 - accuracy: 0.9462\n",
            "Epoch 199/200\n",
            "248/248 [==============================] - 4s 18ms/step - loss: 0.5947 - accuracy: 0.9490\n",
            "Epoch 200/200\n",
            "248/248 [==============================] - 6s 22ms/step - loss: 0.5765 - accuracy: 0.9519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = nn.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxgKzktR7_vg",
        "outputId": "a971128d-c4be-4008-dc11-b676edf8ae4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107/107 [==============================] - 1s 5ms/step - loss: 4.5479 - accuracy: 0.4227\n",
            "Test Loss: 4.547938823699951\n",
            "Test Accuracy: 0.42268040776252747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D74sI2-v8E-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}